{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"seq_gan.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python2","display_name":"Python 2"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"sf4M_UUlAVRJ","colab_type":"text"},"cell_type":"markdown","source":["## Google Drive Mount"]},{"metadata":{"id":"XT6fGhtQAM7z","colab_type":"code","outputId":"2cdca3aa-0872-4828-bec0-fd1408c37fd6","executionInfo":{"status":"ok","timestamp":1543690389885,"user_tz":-540,"elapsed":63345,"user":{"displayName":"김강우","photoUrl":"","userId":"13809575073066285378"}},"colab":{"base_uri":"https://localhost:8080/","height":392}},"cell_type":"code","source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":1,"outputs":[{"output_type":"stream","text":["E: Package 'python-software-properties' has no installation candidate\n","Selecting previously unselected package libfuse2:amd64.\n","(Reading database ... 26397 files and directories currently installed.)\n","Preparing to unpack .../libfuse2_2.9.7-1ubuntu1_amd64.deb ...\n","Unpacking libfuse2:amd64 (2.9.7-1ubuntu1) ...\n","Selecting previously unselected package fuse.\n","Preparing to unpack .../fuse_2.9.7-1ubuntu1_amd64.deb ...\n","Unpacking fuse (2.9.7-1ubuntu1) ...\n","Selecting previously unselected package google-drive-ocamlfuse.\n","Preparing to unpack .../google-drive-ocamlfuse_0.7.1-0ubuntu2~ubuntu18.04.1_amd64.deb ...\n","Unpacking google-drive-ocamlfuse (0.7.1-0ubuntu2~ubuntu18.04.1) ...\n","Setting up libfuse2:amd64 (2.9.7-1ubuntu1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Setting up fuse (2.9.7-1ubuntu1) ...\n","Setting up google-drive-ocamlfuse (0.7.1-0ubuntu2~ubuntu18.04.1) ...\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","··········\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","Please enter the verification code: Access token retrieved correctly.\n"],"name":"stdout"}]},{"metadata":{"id":"kUN0VEOMAPnK","colab_type":"code","colab":{}},"cell_type":"code","source":["!mkdir -p drive\n","!google-drive-ocamlfuse drive"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-mKJlCJNARV1","colab_type":"code","outputId":"577ed2cb-e90a-4772-b6bb-9a28f0045104","executionInfo":{"status":"ok","timestamp":1543690546599,"user_tz":-540,"elapsed":144511,"user":{"displayName":"김강우","photoUrl":"","userId":"13809575073066285378"}},"colab":{"base_uri":"https://localhost:8080/","height":126}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"metadata":{"id":"Sk9sfgUSATFz","colab_type":"code","outputId":"04c366b3-1a74-4c93-eb2a-7517920267bb","executionInfo":{"status":"ok","timestamp":1543690558497,"user_tz":-540,"elapsed":508,"user":{"displayName":"김강우","photoUrl":"","userId":"13809575073066285378"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["cd gdrive/My\\ Drive/SeqGAN"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/SeqGAN\n"],"name":"stdout"}]},{"metadata":{"id":"sbF1pBBvgGZO","colab_type":"code","outputId":"914484f8-ae9d-412a-bf4e-cea7da5d8257","executionInfo":{"status":"ok","timestamp":1543690561805,"user_tz":-540,"elapsed":2683,"user":{"displayName":"김강우","photoUrl":"","userId":"13809575073066285378"}},"colab":{"base_uri":"https://localhost:8080/","height":88}},"cell_type":"code","source":["ls"],"execution_count":5,"outputs":[{"output_type":"stream","text":["dataloader.py      \u001b[0m\u001b[01;34mfigures\u001b[0m/       rollout.py     sequence_gan.py\n","dataloader.pyc     generator.py   rollout.pyc    target_lstm.py\n","discriminator.py   generator.pyc  \u001b[01;34msave\u001b[0m/          target_lstm.pyc\n","discriminator.pyc  README.md      seq_gan.ipynb\n"],"name":"stdout"}]},{"metadata":{"id":"nkyisJYxB1qh","colab_type":"text"},"cell_type":"markdown","source":["### GPU setting"]},{"metadata":{"id":"mz7oKyScB4XH","colab_type":"code","outputId":"a06fd2b3-5bdd-4bd4-c485-eb30070d47d0","executionInfo":{"status":"ok","timestamp":1542215947706,"user_tz":-540,"elapsed":2413,"user":{"displayName":"김강우","photoUrl":"","userId":"13809575073066285378"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"metadata":{"id":"tpKYWqk9GplX","colab_type":"code","colab":{}},"cell_type":"code","source":["# download cuda\n","# ref) https://www.youtube.com/watch?v=UIVf0cwZr5w\n","!apt update -qq;\n","!wget https://developer.nvidia.com/compute/...\n","!dpkg -i cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64-deb;\n","!apt-key add /var/cuda-repo-8-0-local-ga2/7fa2af80.pub;\n","!apt-get update -qq;\n","!apt-get install cuda gcc-5 g++-5 -y -qq;\n","!ln -s /usr/bin/gcc-5 /usr/local/cuda/bin/gcc;\n","!ln -s /usr/bin/g++-5 /usr/local/cuda/bin/g++;\n","!apt install cuda-8.0;"],"execution_count":0,"outputs":[]},{"metadata":{"id":"v6J4b5I8cBRO","colab_type":"code","cellView":"both","colab":{}},"cell_type":"code","source":["# cuda - real~~\n","# ref) https://www.reddit.com/r/CUDA/comments/80dk6p/how_to_install_cudas_toolkit_on_google_colab/\n","!apt update -qq;\n","!wget https://developer.nvidia.com/compute/cuda/8.0/Prod2/local_installers/cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64-deb;\n","!dpkg -i *-deb 2> /dev/null;\n","!apt-key add /var/cuda*/7fa2af80.pub;\n","!apt-get update -qq;\n","!apt-get install cuda gcc-5 g++-5 -y -qq;\n","!ln -s /usr/bin/gcc-5 /usr/local/cuda/bin/gcc;\n","!ln -s /usr/bin/g++-5 /usr/local/cuda/bin/g++;\n","!ln -s /usr/local/cuda/bin/nvcc /usr/bin/nvcc;\n","!apt install cuda-8.0;"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LkTwgaz6HNQz","colab_type":"code","colab":{}},"cell_type":"code","source":["!/usr/local/cuda/bin/nvcc --version\n","!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git\n","%load_ext nvcc_plugin"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xmkYgyoaC2Kh","colab_type":"code","cellView":"form","colab":{}},"cell_type":"code","source":["#@title\n","# install cuda\n","# ref) https://www.reddit.com/r/CUDA/comments/80dk6p/how_to_install_cudas_toolkit_on_google_colab/\n","!apt update -qq;\n","!wget https://developer.nvidia.com/compute/cuda/8.0/Prod2/local_installers/cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64-deb;\n","!dpkg -i *-deb 2> /dev/null;\n","!apt-key add /var/cuda*/7fa2af80.pub;\n","!apt-get update -qq;\n","!apt-get install cuda gcc-5 g++-5 -y -qq;\n","!ln -s /usr/bin/gcc-5 /usr/local/cuda/bin/gcc;\n","!ln -s /usr/bin/g++-5 /usr/local/cuda/bin/g++;\n","!ln -s /usr/local/cuda/bin/nvcc /usr/bin/nvcc;\n","!apt install cuda-8.0;\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"i-SDhgNp_RZh","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","import random\n","from dataloader import Gen_Data_loader, Dis_dataloader\n","from generator import Generator\n","from discriminator import Discriminator\n","from rollout import ROLLOUT\n","from target_lstm import TARGET_LSTM\n","import cPickle"],"execution_count":0,"outputs":[]},{"metadata":{"id":"08_3Tryl_flO","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","#########################################################################################\n","#  Generator  Hyper-parameters\n","######################################################################################\n","EMB_DIM = 32 # embedding dimension\n","HIDDEN_DIM = 32 # hidden state dimension of lstm cell\n","SEQ_LENGTH = 20 # sequence length\n","START_TOKEN = 0\n","PRE_EPOCH_NUM = 120 # supervise (maximum likelihood estimation) epochs\n","SEED = 88\n","BATCH_SIZE = 64\n","\n","#########################################################################################\n","#  Discriminator  Hyper-parameters\n","#########################################################################################\n","dis_embedding_dim = 64\n","dis_filter_sizes = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20]\n","dis_num_filters = [100, 200, 200, 200, 200, 100, 100, 100, 100, 100, 160, 160]\n","dis_dropout_keep_prob = 0.75\n","dis_l2_reg_lambda = 0.2\n","dis_batch_size = 64\n","\n","#########################################################################################\n","#  Basic Training Parameters\n","#########################################################################################\n","TOTAL_BATCH = 200\n","positive_file = 'save/real_data.txt'\n","negative_file = 'save/generator_sample.txt'\n","eval_file = 'save/eval_file.txt'\n","generated_num = 10000"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fN97pqcfgazl","colab_type":"code","colab":{}},"cell_type":"code","source":["def generate_samples(sess, trainable_model, batch_size, generated_num, output_file):\n","    # Generate Samples\n","    generated_samples = []\n","    for _ in range(int(generated_num / batch_size)):\n","        generated_samples.extend(trainable_model.generate(sess))\n","\n","    with open(output_file, 'w') as fout:\n","        for poem in generated_samples:\n","            buffer = ' '.join([str(x) for x in poem]) + '\\n'\n","            fout.write(buffer)\n","\n","\n","def target_loss(sess, target_lstm, data_loader):\n","    # target_loss means the oracle negative log-likelihood tested with the oracle model \"target_lstm\"\n","    # For more details, please see the Section 4 in https://arxiv.org/abs/1609.05473\n","    nll = []\n","    data_loader.reset_pointer()\n","\n","    for it in xrange(data_loader.num_batch):\n","        batch = data_loader.next_batch()\n","        g_loss = sess.run(target_lstm.pretrain_loss, {target_lstm.x: batch})\n","        nll.append(g_loss)\n","\n","    return np.mean(nll)\n","\n","\n","def pre_train_epoch(sess, trainable_model, data_loader):\n","    # Pre-train the generator using MLE for one epoch\n","    supervised_g_losses = []\n","    data_loader.reset_pointer()\n","\n","    for it in xrange(data_loader.num_batch):\n","        batch = data_loader.next_batch()\n","        _, g_loss = trainable_model.pretrain_step(sess, batch)\n","        supervised_g_losses.append(g_loss)\n","\n","    return np.mean(supervised_g_losses)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zNODdFZHgc-y","colab_type":"code","colab":{}},"cell_type":"code","source":["def main():\n","    random.seed(SEED)\n","    np.random.seed(SEED)\n","    assert START_TOKEN == 0\n","\n","    gen_data_loader = Gen_Data_loader(BATCH_SIZE)\n","    likelihood_data_loader = Gen_Data_loader(BATCH_SIZE) # For testing\n","    vocab_size = 5000\n","    dis_data_loader = Dis_dataloader(BATCH_SIZE)\n","\n","    generator = Generator(vocab_size, BATCH_SIZE, EMB_DIM, HIDDEN_DIM, SEQ_LENGTH, START_TOKEN)\n","    target_params = cPickle.load(open('save/target_params.pkl'))\n","    target_lstm = TARGET_LSTM(vocab_size, BATCH_SIZE, EMB_DIM, HIDDEN_DIM, SEQ_LENGTH, START_TOKEN, target_params) # The oracle model\n","\n","    discriminator = Discriminator(sequence_length=20, num_classes=2, vocab_size=vocab_size, embedding_size=dis_embedding_dim, \n","                                filter_sizes=dis_filter_sizes, num_filters=dis_num_filters, l2_reg_lambda=dis_l2_reg_lambda)\n","\n","    config = tf.ConfigProto()\n","    config.gpu_options.allow_growth = True\n","    sess = tf.Session(config=config)\n","    sess.run(tf.global_variables_initializer())\n","\n","    # First, use the oracle model to provide the positive examples, which are sampled from the oracle data distribution\n","    generate_samples(sess, target_lstm, BATCH_SIZE, generated_num, positive_file)\n","    gen_data_loader.create_batches(positive_file)\n","\n","    log = open('save/experiment-log.txt', 'w')\n","    #  pre-train generator\n","    print 'Start pre-training...'\n","    log.write('pre-training...\\n')\n","    for epoch in xrange(PRE_EPOCH_NUM):\n","        loss = pre_train_epoch(sess, generator, gen_data_loader)\n","        if epoch % 5 == 0:\n","            generate_samples(sess, generator, BATCH_SIZE, generated_num, eval_file)\n","            likelihood_data_loader.create_batches(eval_file)\n","            test_loss = target_loss(sess, target_lstm, likelihood_data_loader)\n","            print 'pre-train epoch ', epoch, 'test_loss ', test_loss\n","            buffer = 'epoch:\\t'+ str(epoch) + '\\tnll:\\t' + str(test_loss) + '\\n'\n","            log.write(buffer)\n","\n","    print 'Start pre-training discriminator...'\n","    # Train 3 epoch on the generated data and do this for 50 times\n","    for _ in range(50):\n","        generate_samples(sess, generator, BATCH_SIZE, generated_num, negative_file)\n","        dis_data_loader.load_train_data(positive_file, negative_file)\n","        for _ in range(3):\n","            dis_data_loader.reset_pointer()\n","            for it in xrange(dis_data_loader.num_batch):\n","                x_batch, y_batch = dis_data_loader.next_batch()\n","                feed = {\n","                    discriminator.input_x: x_batch,\n","                    discriminator.input_y: y_batch,\n","                    discriminator.dropout_keep_prob: dis_dropout_keep_prob\n","                }\n","                _ = sess.run(discriminator.train_op, feed)\n","\n","    rollout = ROLLOUT(generator, 0.8)\n","\n","    print '#########################################################################'\n","    print 'Start Adversarial Training...'\n","    log.write('adversarial training...\\n')\n","    for total_batch in range(TOTAL_BATCH):\n","        # Train the generator for one step\n","        for it in range(1):\n","            samples = generator.generate(sess)\n","            rewards = rollout.get_reward(sess, samples, 16, discriminator)\n","            feed = {generator.x: samples, generator.rewards: rewards}\n","            _ = sess.run(generator.g_updates, feed_dict=feed)\n","\n","        # Test\n","        if total_batch % 5 == 0 or total_batch == TOTAL_BATCH - 1:\n","            generate_samples(sess, generator, BATCH_SIZE, generated_num, eval_file)\n","            likelihood_data_loader.create_batches(eval_file)\n","            test_loss = target_loss(sess, target_lstm, likelihood_data_loader)\n","            buffer = 'epoch:\\t' + str(total_batch) + '\\tnll:\\t' + str(test_loss) + '\\n'\n","            print 'total_batch: ', total_batch, 'test_loss: ', test_loss\n","            log.write(buffer)\n","\n","        # Update roll-out parameters\n","        rollout.update_params()\n","\n","        # Train the discriminator\n","        for _ in range(5):\n","            generate_samples(sess, generator, BATCH_SIZE, generated_num, negative_file)\n","            dis_data_loader.load_train_data(positive_file, negative_file)\n","\n","            for _ in range(3):\n","                dis_data_loader.reset_pointer()\n","                for it in xrange(dis_data_loader.num_batch):\n","                    x_batch, y_batch = dis_data_loader.next_batch()\n","                    feed = {\n","                        discriminator.input_x: x_batch,\n","                        discriminator.input_y: y_batch,\n","                        discriminator.dropout_keep_prob: dis_dropout_keep_prob\n","                    }\n","                    _ = sess.run(discriminator.train_op, feed)\n","\n","    log.close()\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JCm53FNXgq1R","colab_type":"code","outputId":"af30dfd2-32cd-4b6f-c10d-b963cebee4d9","executionInfo":{"status":"ok","timestamp":1542249253524,"user_tz":-540,"elapsed":33272230,"user":{"displayName":"김강우","photoUrl":"","userId":"13809575073066285378"}},"colab":{"base_uri":"https://localhost:8080/","height":1406}},"cell_type":"code","source":["if __name__ == '__main__':\n","    main()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From discriminator.py:129: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n","Start pre-training...\n","pre-train epoch  0 test_loss  10.201616\n","pre-train epoch  5 test_loss  9.510182\n","pre-train epoch  10 test_loss  9.246665\n","pre-train epoch  15 test_loss  9.235938\n","pre-train epoch  20 test_loss  9.191811\n","pre-train epoch  25 test_loss  9.145397\n","pre-train epoch  30 test_loss  9.158144\n","pre-train epoch  35 test_loss  9.137041\n","pre-train epoch  40 test_loss  9.148361\n","pre-train epoch  45 test_loss  9.148824\n","pre-train epoch  50 test_loss  9.125338\n","pre-train epoch  55 test_loss  9.127531\n","pre-train epoch  60 test_loss  9.112137\n","pre-train epoch  65 test_loss  9.114475\n","pre-train epoch  70 test_loss  9.115202\n","pre-train epoch  75 test_loss  9.11991\n","pre-train epoch  80 test_loss  9.101248\n","pre-train epoch  85 test_loss  9.105473\n","pre-train epoch  90 test_loss  9.104705\n","pre-train epoch  95 test_loss  9.108667\n","pre-train epoch  100 test_loss  9.110804\n","pre-train epoch  105 test_loss  9.089802\n","pre-train epoch  110 test_loss  9.106358\n","pre-train epoch  115 test_loss  9.101542\n","Start pre-training discriminator...\n","#########################################################################\n","Start Adversarial Training...\n","total_batch:  0 test_loss:  9.097583\n","total_batch:  5 test_loss:  9.026261\n","total_batch:  10 test_loss:  8.967049\n","total_batch:  15 test_loss:  8.908195\n","total_batch:  20 test_loss:  8.897042\n","total_batch:  25 test_loss:  8.872444\n","total_batch:  30 test_loss:  8.853856\n","total_batch:  35 test_loss:  8.84249\n","total_batch:  40 test_loss:  8.843464\n","total_batch:  45 test_loss:  8.849456\n","total_batch:  50 test_loss:  8.819382\n","total_batch:  55 test_loss:  8.832552\n","total_batch:  60 test_loss:  8.830769\n","total_batch:  65 test_loss:  8.821413\n","total_batch:  70 test_loss:  8.844971\n","total_batch:  75 test_loss:  8.856078\n","total_batch:  80 test_loss:  8.861646\n","total_batch:  85 test_loss:  8.856453\n","total_batch:  90 test_loss:  8.850706\n","total_batch:  95 test_loss:  8.855404\n","total_batch:  100 test_loss:  8.847338\n","total_batch:  105 test_loss:  8.851111\n","total_batch:  110 test_loss:  8.854586\n","total_batch:  115 test_loss:  8.843493\n","total_batch:  120 test_loss:  8.836916\n","total_batch:  125 test_loss:  8.840725\n","total_batch:  130 test_loss:  8.832051\n","total_batch:  135 test_loss:  8.826467\n","total_batch:  140 test_loss:  8.827787\n","total_batch:  145 test_loss:  8.817153\n","total_batch:  150 test_loss:  8.814072\n","total_batch:  155 test_loss:  8.810068\n","total_batch:  160 test_loss:  8.823118\n","total_batch:  165 test_loss:  8.812261\n","total_batch:  170 test_loss:  8.827795\n","total_batch:  175 test_loss:  8.824618\n","total_batch:  180 test_loss:  8.818566\n","total_batch:  185 test_loss:  8.816282\n","total_batch:  190 test_loss:  8.836768\n","total_batch:  195 test_loss:  8.822696\n","total_batch:  199 test_loss:  8.829722\n"],"name":"stdout"}]},{"metadata":{"id":"Xy5jkIgtPFh7","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}